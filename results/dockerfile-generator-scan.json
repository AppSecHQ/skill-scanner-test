{
  "skill_name": "dockerfile-gen",
  "skill_path": "/workspace/skills/clawhub-ai-dockerfile",
  "skill_directory": "/workspace/skills/clawhub-ai-dockerfile",
  "is_safe": true,
  "max_severity": "MEDIUM",
  "findings_count": 2,
  "findings": [
    {
      "id": "llm_finding_dockerfile-gen_0",
      "rule_id": "LLM_SOCIAL_ENGINEERING",
      "category": "social_engineering",
      "severity": "MEDIUM",
      "title": "Misleading Skill Description - External Tool Masquerading as Agent Skill",
      "description": "The skill presents itself as an agent skill that generates Dockerfiles, but the instructions exclusively reference 'npx ai-dockerfile', which is an external npm package/CLI tool, not agent-executable code. The skill contains no Python/Bash scripts for the agent to execute. This is deceptive because users expect agent skills to provide capabilities the agent can directly execute, not just documentation for external tools. The skill effectively tricks users into installing and running an external package under the guise of being a native agent capability.",
      "file_path": "SKILL.md",
      "line_number": null,
      "snippet": "Instructions contain only 'npx ai-dockerfile' commands with no agent-executable scripts. Examples: 'npx ai-dockerfile', 'npx ai-dockerfile --base node:20-alpine', 'npx ai-dockerfile --production'. No Python/Bash files present in skill package.",
      "remediation": "Either: (1) Include actual Python/Bash scripts that implement Dockerfile generation logic for the agent to execute, OR (2) Clearly disclose in the description that this is documentation for an external npm tool, not an agent-executable skill. Update description to: 'Documentation and usage guide for the ai-dockerfile npm package' to set accurate expectations.",
      "analyzer": "llm",
      "metadata": {
        "model": "claude-sonnet-4-5-20250929",
        "overall_assessment": "This skill has MEDIUM severity security concerns primarily related to deceptive presentation and lack of transparency. The core issue is that this is not actually an agent skill with executable code, but rather documentation for an external npm package (ai-dockerfile) that requires Node.js and OpenAI API credentials. Users may be misled into: (1) believing this is a native agent capability when it's actually an external tool, (2) exposing OpenAI API credentials to a third-party npm package without understanding the implications, and (3) unknowingly transmitting project source code to OpenAI APIs. The skill lacks transparency about data flows, credential usage, and external dependencies. While no active malicious behavior is detected, the deceptive presentation and undisclosed external dependencies create security risks through user confusion and uninformed credential exposure.",
        "primary_threats": [
          "Social Engineering (Deceptive Skill Presentation)",
          "Undisclosed External API Dependencies",
          "Missing Transparency on Data Transmission",
          "Credential Exposure Risk"
        ],
        "aitech": "AITech-2.1",
        "aitech_name": "Social Engineering",
        "aisubtech": null,
        "aisubtech_name": null,
        "scanner_category": "SOCIAL ENGINEERING",
        "meta_validated": true,
        "meta_confidence": "HIGH",
        "meta_confidence_reason": "Verified by examining actual skill package contents - contains only SKILL.md with no executable scripts. LLM analyzer correctly identified the core deception. This is not a pattern-matching false positive - it's a fundamental architectural problem.",
        "meta_exploitability": "Easy - users are immediately misled upon installation. No technical exploitation needed - the deception is inherent in the skill's design.",
        "meta_impact": "High - Users unknowingly: (1) Execute external npm code not vetted by skill scanner, (2) Expose OPENAI_API_KEY to third-party tool, (3) Potentially transmit project source code to OpenAI APIs without informed consent, (4) Lose trust in the skill ecosystem due to deceptive practices."
      }
    },
    {
      "id": "llm_finding_dockerfile-gen_1",
      "rule_id": "LLM_DATA_EXFILTRATION",
      "category": "data_exfiltration",
      "severity": "MEDIUM",
      "title": "Undisclosed External API Dependency and Credential Requirement",
      "description": "The skill requires OPENAI_API_KEY environment variable but this critical requirement is buried in the documentation and not declared in the YAML manifest. Users may unknowingly expose their OpenAI API credentials to an external npm package without understanding the data flow or security implications. The skill does not disclose what data is sent to OpenAI APIs, whether project source code is transmitted, or how credentials are handled by the external tool.",
      "file_path": "SKILL.md",
      "line_number": 45,
      "snippet": "'Requirements: Node.js 18+. OPENAI_API_KEY required.' - This critical credential requirement is mentioned only in prose, not in manifest metadata. No disclosure of what data is sent to OpenAI or how the API key is used.",
      "remediation": "(1) Add explicit warning in description: 'Requires OPENAI_API_KEY and sends project data to OpenAI APIs'. (2) Document in manifest what data is transmitted externally. (3) Add security warnings about credential exposure to third-party npm packages. (4) Provide transparency about data handling and API usage.",
      "analyzer": "llm",
      "metadata": {
        "model": "claude-sonnet-4-5-20250929",
        "overall_assessment": "This skill has MEDIUM severity security concerns primarily related to deceptive presentation and lack of transparency. The core issue is that this is not actually an agent skill with executable code, but rather documentation for an external npm package (ai-dockerfile) that requires Node.js and OpenAI API credentials. Users may be misled into: (1) believing this is a native agent capability when it's actually an external tool, (2) exposing OpenAI API credentials to a third-party npm package without understanding the implications, and (3) unknowingly transmitting project source code to OpenAI APIs. The skill lacks transparency about data flows, credential usage, and external dependencies. While no active malicious behavior is detected, the deceptive presentation and undisclosed external dependencies create security risks through user confusion and uninformed credential exposure.",
        "primary_threats": [
          "Social Engineering (Deceptive Skill Presentation)",
          "Undisclosed External API Dependencies",
          "Missing Transparency on Data Transmission",
          "Credential Exposure Risk"
        ],
        "aitech": "AITech-8.2",
        "aitech_name": "Data Exfiltration / Exposure",
        "aisubtech": "AISubtech-8.2.3",
        "aisubtech_name": "Data Exfiltration via Agent Tooling",
        "scanner_category": "SECURITY VIOLATION",
        "meta_validated": true,
        "meta_confidence": "HIGH",
        "meta_confidence_reason": "Verified by reading actual SKILL.md content - OPENAI_API_KEY requirement is mentioned but data flows are completely undisclosed. This is a legitimate transparency issue, not a false positive.",
        "meta_exploitability": "Medium - requires user to have OPENAI_API_KEY set, but once set, data transmission happens without informed consent.",
        "meta_impact": "Medium - Potential exposure of: (1) Proprietary source code to OpenAI, (2) API credentials to third-party npm package, (3) Project architecture details. Impact depends on project sensitivity."
      }
    }
  ],
  "scan_duration_seconds": 31.65280532836914,
  "duration_ms": 31652,
  "analyzers_used": [
    "static_analyzer",
    "behavioral_analyzer",
    "llm_analyzer",
    "trigger_analyzer",
    "meta_analyzer"
  ],
  "timestamp": "2026-02-06T00:25:16.627272"
}