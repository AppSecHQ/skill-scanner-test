{
  "skill_name": "githunt",
  "skill_path": "/workspace/skills/clawhub-githunt",
  "skill_directory": "/workspace/skills/clawhub-githunt",
  "is_safe": true,
  "max_severity": "MEDIUM",
  "findings_count": 2,
  "findings": [
    {
      "id": "llm_finding_githunt_0",
      "rule_id": "LLM_DATA_EXFILTRATION",
      "category": "data_exfiltration",
      "severity": "MEDIUM",
      "title": "Potential Data Exfiltration via Third-Party API Without User Consent",
      "description": "The skill makes automated network requests to an external third-party API (api.githunt.ai) that collects and transmits user search queries including location data, technology preferences, and role information. While the API itself appears legitimate for developer search purposes, the skill does not implement any user consent mechanism or data privacy warnings before sending potentially sensitive search criteria to external servers. Users may unknowingly share their hiring intentions, technology interests, and geographic targeting information with a third-party service.",
      "file_path": "scripts/githunt-search.sh",
      "line_number": null,
      "snippet": "curl -s -N -X POST \"$API_URL/rank/users/stream\" \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Accept: text/event-stream\" \\\n  -d \"$payload\"",
      "remediation": "1. Add explicit user consent prompt before making API calls to external services. 2. Include privacy notice in SKILL.md about data transmission to githunt.ai. 3. Implement local caching to minimize repeated API calls. 4. Add option for users to review payload before transmission. 5. Document what data is sent to third-party services in the manifest.",
      "analyzer": "llm",
      "metadata": {
        "model": "claude-sonnet-4-5-20250929",
        "overall_assessment": "The githunt skill is a developer search tool that queries an external API (githunt.ai) to find GitHub developers by location, technology stack, and role. The skill is MODERATELY SAFE with some privacy and transparency concerns. Primary issues: (1) Automated data transmission to third-party API without explicit user consent or privacy warnings, (2) Missing manifest metadata reducing transparency, (3) Lack of API endpoint validation and rate limiting. The skill does not contain malicious code, prompt injection, credential theft, or command injection vulnerabilities. The external API calls are legitimate for the stated purpose, but users should be informed about data sharing. The bash scripts are straightforward with no obfuscation or hidden functionality. Recommended for use with minor improvements to user consent and metadata completeness.",
        "primary_threats": [
          "Data transmission to third-party API without user consent",
          "Missing security metadata (license, compatibility, allowed-tools)",
          "Unbounded API requests without rate limiting"
        ],
        "aitech": "AITech-8.2",
        "aitech_name": "Data Exfiltration / Exposure",
        "aisubtech": "AISubtech-8.2.3",
        "aisubtech_name": "Data Exfiltration via Agent Tooling",
        "scanner_category": "SECURITY VIOLATION",
        "meta_validated": true,
        "meta_confidence": "HIGH",
        "meta_confidence_reason": "LLM analyzer correctly identified that user search data is transmitted to external API without explicit consent mechanism. This is a legitimate transparency/privacy concern, though not a security vulnerability since the API usage is documented and legitimate.",
        "meta_exploitability": "Low - Requires user to actively use the skill, no exploitation vector",
        "meta_impact": "Low - Search metadata exposure only, no credentials or sensitive data"
      }
    },
    {
      "id": "llm_finding_githunt_1",
      "rule_id": "LLM_DATA_EXFILTRATION",
      "category": "data_exfiltration",
      "severity": "LOW",
      "title": "Hardcoded API Endpoint Without Verification",
      "description": "The skill uses a hardcoded external API endpoint (https://api.githunt.ai/v1) with a fallback mechanism via environment variable GITHUNT_API_URL. While environment variable override is good practice, there is no validation of the API endpoint URL, certificate pinning, or integrity checks. This could allow an attacker who controls the environment to redirect API calls to a malicious endpoint for data interception.",
      "file_path": "scripts/githunt-search.sh",
      "line_number": 8,
      "snippet": "API_URL=\"${GITHUNT_API_URL:-https://api.githunt.ai/v1}\"",
      "remediation": "1. Implement URL validation to ensure only HTTPS endpoints are used. 2. Add certificate pinning or domain allowlisting for production API endpoints. 3. Validate API responses for expected structure before processing. 4. Consider adding API endpoint verification in documentation.",
      "analyzer": "llm",
      "metadata": {
        "model": "claude-sonnet-4-5-20250929",
        "overall_assessment": "The githunt skill is a developer search tool that queries an external API (githunt.ai) to find GitHub developers by location, technology stack, and role. The skill is MODERATELY SAFE with some privacy and transparency concerns. Primary issues: (1) Automated data transmission to third-party API without explicit user consent or privacy warnings, (2) Missing manifest metadata reducing transparency, (3) Lack of API endpoint validation and rate limiting. The skill does not contain malicious code, prompt injection, credential theft, or command injection vulnerabilities. The external API calls are legitimate for the stated purpose, but users should be informed about data sharing. The bash scripts are straightforward with no obfuscation or hidden functionality. Recommended for use with minor improvements to user consent and metadata completeness.",
        "primary_threats": [
          "Data transmission to third-party API without user consent",
          "Missing security metadata (license, compatibility, allowed-tools)",
          "Unbounded API requests without rate limiting"
        ],
        "aitech": "AITech-8.2",
        "aitech_name": "Data Exfiltration / Exposure",
        "aisubtech": "AISubtech-8.2.3",
        "aisubtech_name": "Data Exfiltration via Agent Tooling",
        "scanner_category": "SECURITY VIOLATION",
        "meta_validated": true,
        "meta_confidence": "MEDIUM",
        "meta_confidence_reason": "Valid concern about environment variable override, but requires attacker to already have environment access (which is a higher-level compromise). The risk is real but limited in scope.",
        "meta_exploitability": "Low - Requires pre-existing environment variable control",
        "meta_impact": "Medium - Could intercept search queries if environment is compromised"
      }
    }
  ],
  "scan_duration_seconds": 31.347298622131348,
  "duration_ms": 31347,
  "analyzers_used": [
    "static_analyzer",
    "behavioral_analyzer",
    "llm_analyzer",
    "trigger_analyzer",
    "meta_analyzer"
  ],
  "timestamp": "2026-02-06T02:19:52.762071"
}