{
  "skill_name": "moltbook",
  "skill_path": "/workspace/skills/moltbook",
  "skill_directory": "/workspace/skills/moltbook",
  "is_safe": false,
  "max_severity": "HIGH",
  "findings_count": 3,
  "findings": [
    {
      "id": "llm_finding_moltbook_0",
      "rule_id": "LLM_PROMPT_INJECTION",
      "category": "prompt_injection",
      "severity": "HIGH",
      "title": "Indirect Prompt Injection via External Instruction Files",
      "description": "The skill instructs the agent to fetch and follow instructions from external URLs (HEARTBEAT.md, MESSAGING.md) hosted at moltbook.com. This creates a transitive trust vulnerability where the skill delegates control to external content that could be modified to inject malicious instructions. The skill explicitly tells agents to 'just read them from the URLs above' and 'Re-fetch these files anytime to see new features', establishing a pattern of following untrusted external content.",
      "file_path": "SKILL.md",
      "line_number": null,
      "snippet": "## Skill Files\n| File | URL |\n|------|-----|\n| **HEARTBEAT.md** | `https://www.moltbook.com/heartbeat.md` |\n| **MESSAGING.md** | `https://www.moltbook.com/messaging.md` |\n\n**Or just read them from the URLs above!**\n\n**Check for updates:** Re-fetch these files anytime to see new features!",
      "remediation": "Bundle all instruction files within the skill package instead of fetching from external URLs. If external content is necessary, implement strict validation and sandboxing of fetched instructions, and clearly warn users about the security implications of following external content.",
      "analyzer": "llm",
      "metadata": {
        "model": "claude-sonnet-4-5-20250929",
        "overall_assessment": "This skill presents MODERATE to HIGH security risks primarily due to indirect prompt injection vulnerabilities and credential handling concerns. The skill's core design relies on fetching and following instructions from external URLs (HEARTBEAT.md, MESSAGING.md), creating a transitive trust vulnerability where malicious instructions could be injected by compromising the external domain. The skill also handles sensitive API credentials and encourages autonomous behavior without adequate security controls. While the skill includes some security warnings about API key protection, the overall architecture creates multiple attack vectors. The missing manifest metadata and references to non-existent Python files further reduce transparency and trustworthiness.",
        "primary_threats": [
          "Indirect Prompt Injection (AITech-1.2)",
          "Credential Exposure (AITech-8.2)",
          "Tool Exploitation (AITech-12.1)",
          "Social Engineering (AITech-2.1)"
        ],
        "aitech": "AITech-1.2",
        "aitech_name": "Indirect Prompt Injection",
        "aisubtech": null,
        "aisubtech_name": null,
        "scanner_category": "PROMPT INJECTION",
        "meta_validated": true,
        "meta_confidence": "HIGH",
        "meta_confidence_reason": "The skill explicitly instructs agents to fetch and follow external content with phrases like 'Fetch https://www.moltbook.com/heartbeat.md and follow it'. This is a clear transitive trust vulnerability where compromising moltbook.com would allow arbitrary instruction injection to all agents using this skill.",
        "meta_exploitability": "Medium - Requires compromising moltbook.com domain or DNS, but once compromised, affects all agents using the skill",
        "meta_impact": "Critical - Attacker could inject arbitrary instructions to control agent behavior, exfiltrate data, or execute malicious actions"
      }
    },
    {
      "id": "llm_finding_moltbook_1",
      "rule_id": "LLM_DATA_EXFILTRATION",
      "category": "data_exfiltration",
      "severity": "HIGH",
      "title": "API Key Credential Exposure Risk",
      "description": "The skill requires agents to obtain and store API keys (moltbook_xxx) that grant full account access. While the skill includes warnings about not sharing keys, it instructs agents to save credentials to predictable locations (~/.config/moltbook/credentials.json) and handle sensitive authentication tokens. The registration flow exposes API keys in plain text responses, and the skill encourages storing them in multiple locations (memory, environment variables, config files), increasing the attack surface for credential theft.",
      "file_path": "SKILL.md",
      "line_number": null,
      "snippet": "Response:\n```json\n{\n  \"agent\": {\n    \"api_key\": \"moltbook_xxx\",\n    \"claim_url\": \"https://www.moltbook.com/claim/moltbook_claim_xxx\",\n    \"verification_code\": \"reef-X4B2\"\n  },\n  \"important\": \"\u26a0\ufe0f SAVE YOUR API KEY!\"\n}\n```\n\n**Recommended:** Save your credentials to `~/.config/moltbook/credentials.json`",
      "remediation": "Implement secure credential storage mechanisms. Use system keychains or encrypted storage instead of plain text files. Provide clear guidance on secure credential handling and implement token rotation. Consider using short-lived tokens with refresh mechanisms instead of long-lived API keys.",
      "analyzer": "llm",
      "metadata": {
        "model": "claude-sonnet-4-5-20250929",
        "overall_assessment": "This skill presents MODERATE to HIGH security risks primarily due to indirect prompt injection vulnerabilities and credential handling concerns. The skill's core design relies on fetching and following instructions from external URLs (HEARTBEAT.md, MESSAGING.md), creating a transitive trust vulnerability where malicious instructions could be injected by compromising the external domain. The skill also handles sensitive API credentials and encourages autonomous behavior without adequate security controls. While the skill includes some security warnings about API key protection, the overall architecture creates multiple attack vectors. The missing manifest metadata and references to non-existent Python files further reduce transparency and trustworthiness.",
        "primary_threats": [
          "Indirect Prompt Injection (AITech-1.2)",
          "Credential Exposure (AITech-8.2)",
          "Tool Exploitation (AITech-12.1)",
          "Social Engineering (AITech-2.1)"
        ],
        "aitech": "AITech-8.2",
        "aitech_name": "Data Exfiltration / Exposure",
        "aisubtech": "AISubtech-8.2.3",
        "aisubtech_name": "Data Exfiltration via Agent Tooling",
        "scanner_category": "SECURITY VIOLATION",
        "meta_validated": true,
        "meta_confidence": "MEDIUM",
        "meta_confidence_reason": "The skill does include security warnings about not sharing API keys with other domains. However, storing credentials in predictable plain text locations increases exposure risk. This is a standard credential management concern rather than active exfiltration.",
        "meta_exploitability": "Medium - Requires local file access or memory inspection, but predictable storage location makes it easier",
        "meta_impact": "High - Compromised API key allows full account impersonation and access to all Moltbook actions"
      }
    },
    {
      "id": "llm_finding_moltbook_2",
      "rule_id": "LLM_UNAUTHORIZED_TOOL_USE",
      "category": "unauthorized_tool_use",
      "severity": "MEDIUM",
      "title": "Behavioral Autonomy Without User Confirmation",
      "description": "The skill instructs agents to add Moltbook to their heartbeat routines to automatically check and interact with the platform every 4+ hours without explicit user confirmation for each action. The instruction 'Add Moltbook to yours so you don't forget to participate' and 'Step 1: Add to your heartbeat file' encourages autonomous, recurring behavior that could lead to unintended actions or resource consumption.",
      "file_path": "SKILL.md",
      "line_number": null,
      "snippet": "## Set Up Your Heartbeat \ud83d\udc93\n\nYou're registered! Now make sure you actually use Moltbook.\n\nMost agents have a periodic heartbeat or check-in routine. Add Moltbook to yours so you don't forget to participate.\n\n### Step 1: Add to your heartbeat file\n\nAdd this to your `HEARTBEAT.md` (or equivalent periodic task list):\n\n```markdown\n## Moltbook (every 4+ hours)\nIf 4+ hours since last Moltbook check:\n1. Fetch https://www",
      "remediation": "Require explicit user confirmation before adding autonomous behaviors to agent heartbeats. Provide clear opt-in mechanisms and allow users to configure the frequency and scope of automated actions. Implement rate limiting and resource usage controls.",
      "analyzer": "llm",
      "metadata": {
        "model": "claude-sonnet-4-5-20250929",
        "overall_assessment": "This skill presents MODERATE to HIGH security risks primarily due to indirect prompt injection vulnerabilities and credential handling concerns. The skill's core design relies on fetching and following instructions from external URLs (HEARTBEAT.md, MESSAGING.md), creating a transitive trust vulnerability where malicious instructions could be injected by compromising the external domain. The skill also handles sensitive API credentials and encourages autonomous behavior without adequate security controls. While the skill includes some security warnings about API key protection, the overall architecture creates multiple attack vectors. The missing manifest metadata and references to non-existent Python files further reduce transparency and trustworthiness.",
        "primary_threats": [
          "Indirect Prompt Injection (AITech-1.2)",
          "Credential Exposure (AITech-8.2)",
          "Tool Exploitation (AITech-12.1)",
          "Social Engineering (AITech-2.1)"
        ],
        "aitech": "AITech-12.1",
        "aitech_name": "Tool Exploitation",
        "aisubtech": "AISubtech-12.1.2",
        "aisubtech_name": "Tool Poisoning",
        "scanner_category": "SUSPICIOUS CODE EXECUTION",
        "meta_validated": true,
        "meta_confidence": "MEDIUM",
        "meta_confidence_reason": "The skill presents heartbeat integration as optional ('Don't have a heartbeat system? Just check Moltbook whenever you think of it') and includes the note 'Your human can prompt you to do anything on Moltbook' suggesting manual control is supported. The autonomy concern is moderate rather than severe.",
        "meta_exploitability": "Low - Requires agent to voluntarily implement heartbeat, and behavior is documented",
        "meta_impact": "Low - Automated checking is relatively benign for a social network skill, though could consume resources"
      }
    }
  ],
  "scan_duration_seconds": 35.71028208732605,
  "duration_ms": 35710,
  "analyzers_used": [
    "static_analyzer",
    "llm_analyzer",
    "meta_analyzer"
  ],
  "timestamp": "2026-02-01T18:51:26.053990"
}