{
  "skill_name": "home-assistant",
  "skill_path": "/workspace/skills/clawhub-home-assistant",
  "skill_directory": "/workspace/skills/clawhub-home-assistant",
  "is_safe": false,
  "max_severity": "HIGH",
  "findings_count": 3,
  "findings": [
    {
      "id": "llm_finding_home-assistant_0",
      "rule_id": "LLM_DATA_EXFILTRATION",
      "category": "data_exfiltration",
      "severity": "HIGH",
      "title": "Hardcoded Credential Storage in Plaintext Configuration File",
      "description": "The skill instructs users to store Home Assistant credentials (URL and long-lived access token) in plaintext configuration files at ~/.config/home-assistant/config.json or as environment variables. Long-lived access tokens provide full API access to Home Assistant, which controls physical smart home devices. Storing these credentials in plaintext creates significant risk of credential theft if the user's system is compromised. The token provides complete control over the smart home including locks, cameras, and other security devices.",
      "file_path": "SKILL.md",
      "line_number": null,
      "snippet": "Create `~/.config/home-assistant/config.json`:\n```json\n{\n  \"url\": \"https://your-ha-instance.duckdns.org\",\n  \"token\": \"your-long-lived-access-token\"\n}\n```",
      "remediation": "Implement secure credential storage using system keychains (macOS Keychain, Windows Credential Manager, Linux Secret Service). Use encrypted storage with appropriate file permissions (0600). Consider implementing token rotation and using short-lived tokens where possible. Add warnings about credential security in documentation.",
      "analyzer": "llm",
      "metadata": {
        "model": "claude-sonnet-4-5-20250929",
        "overall_assessment": "The home-assistant skill provides legitimate smart home control functionality but has MODERATE security concerns primarily around credential management. The skill requires users to store sensitive long-lived access tokens in plaintext files or environment variables, creating credential exposure risks. The bash script implementation lacks robust input validation and could be vulnerable to injection attacks if malicious entity IDs are provided. The skill does not implement secure credential storage mechanisms. However, the skill's core functionality is legitimate and does not contain malicious code, data exfiltration attempts, or prompt injection. The primary risks are architectural (credential storage) and implementation quality (input validation) rather than intentional threats. With improved credential management and input validation, this skill would be suitable for use.",
        "primary_threats": [
          "Credential exposure via plaintext storage",
          "Insufficient input validation in shell scripts",
          "Missing security metadata"
        ],
        "aitech": "AITech-8.2",
        "aitech_name": "Data Exfiltration / Exposure",
        "aisubtech": "AISubtech-8.2.3",
        "aisubtech_name": "Data Exfiltration via Agent Tooling",
        "scanner_category": "SECURITY VIOLATION",
        "meta_validated": true,
        "meta_confidence": "HIGH",
        "meta_confidence_reason": "LLM analyzer correctly identified that long-lived access tokens stored in plaintext pose a real credential theft risk. This is a legitimate architectural security concern, not a false positive.",
        "meta_exploitability": "Medium - Requires local system access, but tokens provide full smart home control once obtained",
        "meta_impact": "High - Complete control over physical smart home devices including security systems"
      }
    },
    {
      "id": "llm_finding_home-assistant_1",
      "rule_id": "LLM_DATA_EXFILTRATION",
      "category": "data_exfiltration",
      "severity": "MEDIUM",
      "title": "Credential Exposure via Environment Variables",
      "description": "The skill recommends storing Home Assistant credentials in environment variables (HA_URL and HA_TOKEN). Environment variables can be exposed through process listings, shell history, log files, and child processes. This creates multiple vectors for credential leakage, especially in shared or multi-user environments.",
      "file_path": "SKILL.md",
      "line_number": null,
      "snippet": "### Option 2: Environment Variables\n\n```bash\nexport HA_URL=\"http://homeassistant.local:8123\"\nexport HA_TOKEN=\"your-long-lived-access-token\"\n```",
      "remediation": "Prioritize file-based configuration with proper permissions over environment variables. If environment variables must be used, document the security implications and recommend using them only in isolated, single-user environments. Implement credential masking in any logging or error output.",
      "analyzer": "llm",
      "metadata": {
        "model": "claude-sonnet-4-5-20250929",
        "overall_assessment": "The home-assistant skill provides legitimate smart home control functionality but has MODERATE security concerns primarily around credential management. The skill requires users to store sensitive long-lived access tokens in plaintext files or environment variables, creating credential exposure risks. The bash script implementation lacks robust input validation and could be vulnerable to injection attacks if malicious entity IDs are provided. The skill does not implement secure credential storage mechanisms. However, the skill's core functionality is legitimate and does not contain malicious code, data exfiltration attempts, or prompt injection. The primary risks are architectural (credential storage) and implementation quality (input validation) rather than intentional threats. With improved credential management and input validation, this skill would be suitable for use.",
        "primary_threats": [
          "Credential exposure via plaintext storage",
          "Insufficient input validation in shell scripts",
          "Missing security metadata"
        ],
        "aitech": "AITech-8.2",
        "aitech_name": "Data Exfiltration / Exposure",
        "aisubtech": "AISubtech-8.2.3",
        "aisubtech_name": "Data Exfiltration via Agent Tooling",
        "scanner_category": "SECURITY VIOLATION",
        "meta_validated": true,
        "meta_confidence": "HIGH",
        "meta_confidence_reason": "Environment variables are a known credential exposure vector. This is a valid security concern, though less severe than plaintext files since they're not persisted to disk by default.",
        "meta_exploitability": "Medium - Requires process inspection access or shell history access",
        "meta_impact": "High - Same credential theft impact as finding #1"
      }
    },
    {
      "id": "llm_finding_home-assistant_2",
      "rule_id": "LLM_COMMAND_INJECTION",
      "category": "command_injection",
      "severity": "MEDIUM",
      "title": "Insufficient Input Validation in Shell Script",
      "description": "The bash script (ha.sh) accepts entity IDs and other parameters from command-line arguments without proper validation or sanitization before passing them to curl commands and JSON payloads. While the script uses proper quoting, malicious entity IDs or parameters could potentially be crafted to exploit JSON injection or cause unexpected behavior. The script constructs JSON payloads using string interpolation which could be vulnerable to injection if entity IDs contain special characters.",
      "file_path": "scripts/ha.sh",
      "line_number": null,
      "snippet": "api -X POST \"$HA_URL/api/services/$domain/turn_on\" \\\n  -d \"{\\\"entity_id\\\": \\\"$entity\\\", \\\"brightness\\\": $brightness}\"",
      "remediation": "Implement strict input validation for entity IDs (validate format: domain.entity_name with alphanumeric and underscore only). Use jq to construct JSON payloads instead of string interpolation to prevent injection. Add parameter validation for numeric values like brightness. Implement allowlisting for valid domains and service names.",
      "analyzer": "llm",
      "metadata": {
        "model": "claude-sonnet-4-5-20250929",
        "overall_assessment": "The home-assistant skill provides legitimate smart home control functionality but has MODERATE security concerns primarily around credential management. The skill requires users to store sensitive long-lived access tokens in plaintext files or environment variables, creating credential exposure risks. The bash script implementation lacks robust input validation and could be vulnerable to injection attacks if malicious entity IDs are provided. The skill does not implement secure credential storage mechanisms. However, the skill's core functionality is legitimate and does not contain malicious code, data exfiltration attempts, or prompt injection. The primary risks are architectural (credential storage) and implementation quality (input validation) rather than intentional threats. With improved credential management and input validation, this skill would be suitable for use.",
        "primary_threats": [
          "Credential exposure via plaintext storage",
          "Insufficient input validation in shell scripts",
          "Missing security metadata"
        ],
        "aitech": "AITech-9.1",
        "aitech_name": "Model or Agentic System Manipulation",
        "aisubtech": "AISubtech-9.1.4",
        "aisubtech_name": "Injection Attacks (SQL, Command Execution, XSS)",
        "scanner_category": "INJECTION ATTACK",
        "meta_validated": true,
        "meta_confidence": "MEDIUM",
        "meta_confidence_reason": "The script uses proper shell quoting which mitigates command injection, but JSON injection is still possible with crafted entity IDs. Real-world exploitability depends on whether entity IDs can be attacker-controlled (unlikely in normal usage, but possible if agent processes untrusted input).",
        "meta_exploitability": "Low-Medium - Requires attacker to control entity_id parameter, which is typically from trusted Home Assistant API responses",
        "meta_impact": "Medium - Could manipulate Home Assistant API calls to affect unintended devices"
      }
    }
  ],
  "scan_duration_seconds": 34.33225131034851,
  "duration_ms": 34332,
  "analyzers_used": [
    "static_analyzer",
    "behavioral_analyzer",
    "llm_analyzer",
    "trigger_analyzer",
    "meta_analyzer"
  ],
  "timestamp": "2026-02-06T03:00:44.442612"
}